{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport json\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport os\nimport gc\n\nfrom tensorflow.keras import layers, optimizers\nfrom keras.models import Model\nfrom keras.layers import Input,Dense,LSTM,Reshape,Dropout\nfrom keras.utils import Sequence\nimport os, psutil ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-30T23:56:28.221616Z","iopub.execute_input":"2023-04-30T23:56:28.221996Z","iopub.status.idle":"2023-04-30T23:56:28.228233Z","shell.execute_reply.started":"2023-04-30T23:56:28.221964Z","shell.execute_reply":"2023-04-30T23:56:28.226965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cpu_stats():\n    pid = os.getpid()\n    py = psutil.Process(pid)\n    memory_use = py.memory_info()[0] / 2. ** 30\n    return 'memory GB:' + str(np.round(memory_use, 2))","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:56:28.272622Z","iopub.execute_input":"2023-04-30T23:56:28.273878Z","iopub.status.idle":"2023-04-30T23:56:28.279545Z","shell.execute_reply.started":"2023-04-30T23:56:28.273818Z","shell.execute_reply":"2023-04-30T23:56:28.278332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load and prepear dataset","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/asl-signs/sign_to_prediction_index_map.json') as f:\n    sign_ids = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:56:28.419225Z","iopub.execute_input":"2023-04-30T23:56:28.420469Z","iopub.status.idle":"2023-04-30T23:56:28.428069Z","shell.execute_reply.started":"2023-04-30T23:56:28.420409Z","shell.execute_reply":"2023-04-30T23:56:28.426529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LANDMARK_IDX = [0,9,11,13,14,17,117,118,119,199,346,347,348] + list(range(468,543))\nLIPS_IDXS =[0,9,11,13,14,17,37,39,40,61,78,80,81,82,84,87,88,91,95,117,118,119,\n                146,178,181,185,191,199,267,269,270,291,308,310,311,312,314,317,318,321,\n                324,346,347,348,375,402,405,409,415]\nLEFT_HAND_IDXS = np.arange(468,489)\n\nREF_POSE_IDXS=[489]\nLEFT_POSE_IDXS=[490,491,492,496,498,500,502,504,506,508,510,512,514,516,518,520]\nRIGHT_POSE_IDXS=[493,494,495,497,499,501,503,505,507,509,511,513,515,517,519,521]\nDIFF_LEFT_POSE_IDXS=[1,2,3,7,9,11,13,15,17,19,21,23,25,27,29,31]\nDIFF_RIGHT_POSE_IDXS=[4,5,6,8,10,12,14,16,18,20,22,24,26,28,30,32]\nNEW_LEFT_POSE_IDXS=[490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505]\nNEW_RIGHT_POSE_IDXS=[506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521]\n\nPOSE_IDXS = np.arange(489,522) #Se corrigio post flip para no intercalar los valores nuevamente\nRIGHT_HAND_IDXS = np.arange(522,543)\n\nLANDMARK_IDX = list(LIPS_IDXS)+list(POSE_IDXS)+list(LEFT_HAND_IDXS)+list(RIGHT_HAND_IDXS)\n\n# LANDMARK_IDX = range(0,543)\nDATA_COLUMNS    = ['x', 'y', 'z']\n# DATA_COLUMNS    = ['x', 'y']\nROWS_PER_FRAME  = 543\nNUM_SHARDS      = 2\nSAVE_PATH       = '/tmp/GoogleISLDataset'\nBATCH_SIZE  = 64\ndata_dir = \"/kaggle/input/asl-signs\"\nN_FRAMES_NORM=64\nCLASS_COUNT=250\nLEARNING_RATE=0.001","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:56:28.538580Z","iopub.execute_input":"2023-04-30T23:56:28.539860Z","iopub.status.idle":"2023-04-30T23:56:28.552202Z","shell.execute_reply.started":"2023-04-30T23:56:28.539801Z","shell.execute_reply":"2023-04-30T23:56:28.551006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_relevant_data_subset(pq_path):\n    data = pd.read_parquet('/kaggle/input/asl-signs/'+pq_path, columns=['x', 'y', 'z'])\n    n_frames = int(len(data) / 543)\n    data = data.values.astype(np.float32)\n    return data.reshape(n_frames, 543, 3)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:56:28.589202Z","iopub.execute_input":"2023-04-30T23:56:28.589753Z","iopub.status.idle":"2023-04-30T23:56:28.594342Z","shell.execute_reply.started":"2023-04-30T23:56:28.589722Z","shell.execute_reply":"2023-04-30T23:56:28.593659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_json(path):\n    with open(path, \"r\") as file:\n        json_data = json.load(file)\n    return json_data","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:56:28.642505Z","iopub.execute_input":"2023-04-30T23:56:28.643144Z","iopub.status.idle":"2023-04-30T23:56:28.648023Z","shell.execute_reply.started":"2023-04-30T23:56:28.643105Z","shell.execute_reply":"2023-04-30T23:56:28.647068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/asl-signs/train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:56:28.687889Z","iopub.execute_input":"2023-04-30T23:56:28.688595Z","iopub.status.idle":"2023-04-30T23:56:28.797702Z","shell.execute_reply.started":"2023-04-30T23:56:28.688546Z","shell.execute_reply":"2023-04-30T23:56:28.795492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:56:28.801834Z","iopub.execute_input":"2023-04-30T23:56:28.802359Z","iopub.status.idle":"2023-04-30T23:56:28.813246Z","shell.execute_reply.started":"2023-04-30T23:56:28.802325Z","shell.execute_reply":"2023-04-30T23:56:28.811714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s2p_map = read_json(os.path.join(data_dir, \"sign_to_prediction_index_map.json\"))\np2s_map = {v: k for k, v in s2p_map.items()}\n\nencoder = lambda x: s2p_map.get(x)\ndecoder = lambda x: p2s_map.get(x)\n\ndf[\"label\"] = df[\"sign\"].map(encoder)\nprint(f\"shape = {df.shape}\")\n\ndf=df.sample(frac=1,random_state=42)\ndf.reset_index(drop=True,inplace=True)\ndf.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:56:28.815167Z","iopub.execute_input":"2023-04-30T23:56:28.815476Z","iopub.status.idle":"2023-04-30T23:56:28.878570Z","shell.execute_reply.started":"2023-04-30T23:56:28.815447Z","shell.execute_reply":"2023-04-30T23:56:28.877559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df,val_df = train_test_split(\n    df, test_size=0.2, stratify=df['label'], random_state=42\n)\ntrain_df.reset_index(drop=True,inplace=True)\nval_df.reset_index(drop=True,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:56:28.880177Z","iopub.execute_input":"2023-04-30T23:56:28.881826Z","iopub.status.idle":"2023-04-30T23:56:28.932675Z","shell.execute_reply.started":"2023-04-30T23:56:28.881788Z","shell.execute_reply":"2023-04-30T23:56:28.931420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_rotation_matrix(degree):\n    tita_rad=degree*np.pi/180\n    R=np.array([[np.cos(tita_rad),-np.sin(tita_rad)],[np.sin(tita_rad),np.cos(tita_rad)]])\n    return tf.cast(tf.constant(R), tf.float32)\n\ndef get_augmentation_x(x_samp,angle=0):\n    # Original mass center | shape(frames, 124, 3) 1,frames,landmarks_id,xyz\n    # Landmarks is the dimension to mean    \n    x_samp_xy=tf.gather(x_samp, [0,1], axis=2) # --> shape(frames, 124, 2)\n    mass_center_orig=tf.experimental.numpy.nanmean(x_samp_xy,axis=1) # --> shape(frames, 2)\n    \n    # Expand dim from sum with rotated tensor\n    mass_center_orig = tf.expand_dims(mass_center_orig, axis=1) # --> shape(frames,1, 2)\n\n    R=get_rotation_matrix(angle)  \n    # Rotation\n    # x_samp[:,:,:,[0, 1]]=np.matmul(x_samp[:,:,:,[0, 1]],R) \n    x_samp_rot_xy=tf.matmul(tf.cast(tf.gather(x_samp,tf.range(0,2), axis=2), tf.float32),R) # --> shape(frames, 124, 2)\n    x_samp_rot_z=tf.gather(x_samp,tf.range(2,3), axis=2) # Really z is not rotated but the name is for normalization \n    \n    # Rotation mass center\n    mass_center_rot=tf.experimental.numpy.nanmean(x_samp_rot_xy,axis=1) # --> shape(frames, 2)\n\n    # Expand dim from sum with rotated tensor\n    mass_center_rot = tf.expand_dims(mass_center_rot, axis=1) # --> shape(frames,1, 2)\n\n    # Mass center difference\n    mass_center_dif=mass_center_orig-mass_center_rot    \n    x_samp_rot_xy=x_samp_rot_xy+mass_center_dif\n    \n    # We have to concat to get a shape (None,len(LANDMARK_IDX),3)\n    x_samp_rot = tf.concat([x_samp_rot_xy, x_samp_rot_z], axis=2)\n    return x_samp_rot    ","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:56:28.959503Z","iopub.execute_input":"2023-04-30T23:56:28.960559Z","iopub.status.idle":"2023-04-30T23:56:28.970060Z","shell.execute_reply.started":"2023-04-30T23:56:28.960479Z","shell.execute_reply":"2023-04-30T23:56:28.968976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_augm_flip(inputs):    \n    out_center_flipx=tf.gather(inputs,[0],axis=-1)*(-1)\n    out_center_flipyz=tf.gather(inputs,[1,2],axis=-1)\n    out_center_flip = tf.concat([out_center_flipx,out_center_flipyz],axis=-1)\n    \n    tf_lips=tf.gather(out_center_flip,np.arange(0,468),axis=1) # Se tiene en cuenta toda la cabeza\n    tf_lhand=tf.gather(out_center_flip,LEFT_HAND_IDXS,axis=1)\n    tf_ref_pose=tf.gather(out_center_flip,REF_POSE_IDXS,axis=1)\n    tf_lpose=tf.gather(out_center_flip,NEW_LEFT_POSE_IDXS,axis=1)\n    tf_rpose=tf.gather(out_center_flip,NEW_RIGHT_POSE_IDXS,axis=1)\n    tf_rhand=tf.gather(out_center_flip,RIGHT_HAND_IDXS,axis=1)\n    \n    out=tf.concat([tf_lips,tf_rhand,tf_ref_pose,tf_rpose,tf_lpose,tf_lhand],axis=1)\n    \n    return out","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:56:29.119700Z","iopub.execute_input":"2023-04-30T23:56:29.120179Z","iopub.status.idle":"2023-04-30T23:56:29.130933Z","shell.execute_reply.started":"2023-04-30T23:56:29.120136Z","shell.execute_reply":"2023-04-30T23:56:29.128855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_augm_time(x):\n    # shape(frames, 124, 3)\n    if (x.shape[0]<=6):\n        action='slow'\n        ratio=4        \n    elif (x.shape[0]>6) & (x.shape[0]<=12):\n        action='slow'\n        ratio=2\n    elif (x.shape[0]>32) & (x.shape[0]<=64):\n        action='fast' \n        ratio=2\n    elif (x.shape[0]>32) & (x.shape[0]<64):\n        action='fast'  \n        ratio=3\n    elif (x.shape[0]>64) & (x.shape[0]<128):\n        action='fast'  \n        ratio=4\n    elif (x.shape[0]>=128):\n        action='fast'  \n        ratio=8\n    else:\n        return x\n        \n    if action=='fast':\n        accelerate=tf.range(0, x.shape[0], delta=ratio)\n        x=tf.gather(x,accelerate,axis=0)\n    elif action=='slow':\n        x=tf.repeat(x,repeats=ratio,axis=0)\n    else:\n        return x \n    return x","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:56:29.177188Z","iopub.execute_input":"2023-04-30T23:56:29.177601Z","iopub.status.idle":"2023-04-30T23:56:29.189454Z","shell.execute_reply.started":"2023-04-30T23:56:29.177563Z","shell.execute_reply":"2023-04-30T23:56:29.187898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize(tensor):\n    tf_lips=tf.gather(tensor,np.arange(0,468),axis=1) # LIPS HARCODEADO\n    tf_lhand=tf.gather(tensor,LEFT_HAND_IDXS,axis=1)\n    tf_pose=tf.gather(tensor,np.arange(489,522),axis=1)\n    tf_rhand=tf.gather(tensor,RIGHT_HAND_IDXS,axis=1)\n    \n    # LIPS\n    tf_lips_x=tf.gather(tf_lips,[0],axis=-1)\n    tf_lips_y=tf.gather(tf_lips,[1],axis=-1)\n    tf_lips_z=tf.gather(tf_lips,[2],axis=-1)\n    \n    tf_lips=tf.concat([tf_lips_x-tf.gather(tf_lips_x,[0],axis=1),\n                       tf_lips_y-tf.gather(tf_lips_y,[0],axis=1),\n                       tf_lips_z-tf.gather(tf_lips_z,[0],axis=1)],axis=-1)\n    \n    # LHANDS\n    tf_lhand_x=tf.gather(tf_lhand,[0],axis=-1)\n    tf_lhand_y=tf.gather(tf_lhand,[1],axis=-1)\n    tf_lhand_z=tf.gather(tf_lhand,[2],axis=-1)\n    \n    tf_lhand=tf.concat([tf_lhand_x-tf.gather(tf_lhand_x,[0],axis=1),\n                       tf_lhand_y-tf.gather(tf_lhand_y,[0],axis=1),\n                       tf_lhand_z-tf.gather(tf_lhand_z,[0],axis=1)],axis=-1)\n    \n    # POSE\n    tf_pose_x=tf.gather(tf_pose,[0],axis=-1)\n    tf_pose_y=tf.gather(tf_pose,[1],axis=-1)\n    tf_pose_z=tf.gather(tf_pose,[2],axis=-1)\n    \n    tf_pose=tf.concat([tf_pose_x-tf.gather(tf_pose_x,[0],axis=1),\n                       tf_pose_y-tf.gather(tf_pose_y,[0],axis=1),\n                       tf_pose_z-tf.gather(tf_pose_z,[0],axis=1)],axis=-1)\n \n    # RIGHT HANDS\n    tf_rhand_x=tf.gather(tf_rhand,[0],axis=-1)\n    tf_rhand_y=tf.gather(tf_rhand,[1],axis=-1)\n    tf_rhand_z=tf.gather(tf_rhand,[2],axis=-1)\n    \n    tf_rhand=tf.concat([tf_rhand_x-tf.gather(tf_rhand_x,[0],axis=1),\n                       tf_rhand_y-tf.gather(tf_rhand_y,[0],axis=1),\n                       tf_rhand_z-tf.gather(tf_rhand_z,[0],axis=1)],axis=-1)\n    \n    tf_pose_ref=tf.gather(tf_pose,[0],axis=1)\n    tf_pose_left=tf.gather(tf_pose,DIFF_LEFT_POSE_IDXS,axis=1)\n    tf_pose_right=tf.gather(tf_pose,DIFF_RIGHT_POSE_IDXS,axis=1)\n    \n    out=tf.concat([tf_lips,tf_lhand,tf_pose_ref,tf_pose_left,tf_pose_right,tf_rhand],axis=1)\n    return out","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:56:29.229197Z","iopub.execute_input":"2023-04-30T23:56:29.229615Z","iopub.status.idle":"2023-04-30T23:56:29.247280Z","shell.execute_reply.started":"2023-04-30T23:56:29.229580Z","shell.execute_reply":"2023-04-30T23:56:29.246081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rotated_part(tensor,angle=0,part='lhand',plane='xy'):\n    # SIEMPRE se debe poner despues de la funcion normalizada\n    # Original mass center | shape(frames, 124, 3) 1,frames,landmarks_id,xyz\n    tf_lips=tf.gather(tensor,np.arange(0,468),axis=1) # LIPS HARCODEADO\n    tf_lhand=tf.gather(tensor,LEFT_HAND_IDXS,axis=1)\n    tf_pose=tf.gather(tensor,np.arange(489,522),axis=1)\n    tf_rhand=tf.gather(tensor,RIGHT_HAND_IDXS,axis=1)\n\n    # Landmarks is the dimension to mean   \n    plane_rot=tf.constant([0,1]) #x,y\n    plane_fix=tf.constant([2])   #z\n    \n    if part=='lips':\n        x_samp=tf_lips\n    elif part=='lhand':\n        x_samp=tf_lhand\n    elif part=='pose':\n        x_samp=tf_pose\n    elif part=='rhand':\n        x_samp=tf_rhand\n    else:\n        None\n    \n    x_samp_x=tf.gather(x_samp,[0], axis=2) # --> shape(frames, 124, 2)\n    x_samp_y=tf.gather(x_samp,[1], axis=2) # --> shape(frames, 124, 2)\n    x_samp_z=tf.zeros(shape=(x_samp.shape[0],x_samp.shape[1],1)) # --> shape(frames, 124, 2)\n    \n    if plane=='xy':\n        x_to_rot=tf.concat([x_samp_x,x_samp_y],axis=2)\n    elif plane=='yz':\n        x_to_rot=tf.concat([x_samp_y,x_samp_z],axis=2)\n    else: #'xz'\n        x_to_rot=tf.concat([x_samp_x,x_samp_z],axis=2)\n\n    R=get_rotation_matrix(angle)  \n    # Rotation\n    # x_samp[:,:,:,[0, 1]]=np.matmul(x_samp[:,:,:,[0, 1]],R) \n    x_samp_rot=tf.matmul(tf.cast(x_to_rot, tf.float32),R) # --> shape(frames, 124, 2)\n    \n    \n    # We have to concat to get a shape (None,len(LANDMARK_IDX),3)\n    if plane=='xy':\n        x_samp_rot = tf.concat([x_samp_rot, x_samp_z], axis=2) #!OJO ACA CUANDO SE SUMA\n    elif plane=='yz':\n        x_samp_rot = tf.concat([x_samp_x, x_samp_rot], axis=2)\n    else: #'xz'\n        x_samp_rot_x=tf.gather(x_samp_rot,[0], axis=2)\n        x_samp_rot_z=tf.gather(x_samp_rot,[1], axis=2)\n        x_samp_rot = tf.concat([x_samp_rot_x,x_samp_y, x_samp_rot_z], axis=2)\n        \n    \n    if part=='lips':\n        out=tf.concat([x_samp_rot,tf_lhand,tf_pose,tf_rhand],axis=1)\n    elif part=='lhand':\n        out=tf.concat([tf_lips,x_samp_rot,tf_pose,tf_rhand],axis=1)\n    elif part=='pose':\n        out=tf.concat([tf_lips,tf_lhand,x_samp_rot,tf_rhand],axis=1)\n    elif part=='rhand':\n        out=tf.concat([tf_lips,tf_lhand,tf_pose,x_samp_rot],axis=1)\n    else:\n        out=None  \n        \n    return out ","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:56:29.282920Z","iopub.execute_input":"2023-04-30T23:56:29.283303Z","iopub.status.idle":"2023-04-30T23:56:29.300034Z","shell.execute_reply.started":"2023-04-30T23:56:29.283271Z","shell.execute_reply":"2023-04-30T23:56:29.298777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocesing with Ragged Tensor","metadata":{}},{"cell_type":"code","source":"def tf_get_features(ftensor):\n    def feat_wrapper(ftensor):\n        x=load_relevant_data_subset(ftensor.numpy().decode('utf-8'))\n        return x\n    return tf.py_function(\n        feat_wrapper,\n        [ftensor],\n        Tout=tf.float32\n    )\n\ndef tf_get_features_augm(ftensor,angle):\n    def feat_wrapper(ftensor):\n        x=get_augmentation_x(ftensor,angle)\n        return x\n    return tf.py_function(\n        feat_wrapper,\n        [ftensor],\n        Tout=tf.float32\n    )\n\ndef tf_get_features_augm_time(ftensor):\n    def feat_wrapper(ftensor):\n        x=get_augm_time(ftensor)\n        return x\n    return tf.py_function(\n        feat_wrapper,\n        [ftensor],\n        Tout=tf.float32\n    )\n\ndef tf_get_features_augm_flip(ftensor):\n    def feat_wrapper(ftensor):\n        x=get_augm_flip(ftensor)\n        return x\n    return tf.py_function(\n        feat_wrapper,\n        [ftensor],\n        Tout=tf.float32\n    )\n\ndef tf_get_features_normalize(ftensor):\n    def feat_wrapper(ftensor):\n        x=normalize(ftensor)\n        return x\n    return tf.py_function(\n        feat_wrapper,\n        [ftensor],\n        Tout=tf.float32\n    )\n\ndef tf_get_features_rotated_part(ftensor,angle=0,part='lhand',plane='xy'):\n    def feat_wrapper(ftensor):\n        x=rotated_part(ftensor,angle=0,part='lhand',plane='xy')\n        return x\n    return tf.py_function(\n        feat_wrapper,\n        [ftensor],\n        Tout=tf.float32\n    )","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:56:29.333187Z","iopub.execute_input":"2023-04-30T23:56:29.333588Z","iopub.status.idle":"2023-04-30T23:56:29.343930Z","shell.execute_reply.started":"2023-04-30T23:56:29.333552Z","shell.execute_reply":"2023-04-30T23:56:29.342906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PreprocessLayer(tf.keras.layers.Layer):\n    def __init__(self):\n        super(PreprocessLayer, self).__init__()\n        \n    @tf.function(\n        input_signature=(tf.TensorSpec(shape=[None,len(LANDMARK_IDX),len(DATA_COLUMNS)], dtype=tf.float32),),\n    )\n    def call(self, data0):\n        if len(DATA_COLUMNS)<3:\n            data0 = tf.gather(data0, [0,1], axis=2)\n        \n        N_FRAMES0 = tf.shape(data0)[0]\n        \n        data=data0\n        frames_landmark_non_nan_sum  = tf.math.reduce_sum(\n                    tf.where(tf.math.is_nan(tf.gather(data0, tf.range(0,len(LANDMARK_IDX)), axis=1)), 0, 1),\n                    axis=[1, 2],\n                )\n        non_empty_frames_idxs = tf.where(frames_landmark_non_nan_sum > 0)\n        non_empty_frames_idxs = tf.squeeze(non_empty_frames_idxs, axis=1)\n        data = tf.gather(data0, non_empty_frames_idxs, axis=0)\n        \n        # Cast Indices in float32 to be compatible with Tensorflow Lite\n        non_empty_frames_idxs = tf.cast(non_empty_frames_idxs, tf.float32)\n        # Normalize to start with 0\n        non_empty_frames_idxs -= tf.reduce_min(non_empty_frames_idxs)\n        \n        # Number of Frames in Filtered Video\n        N_FRAMES = tf.shape(data)[0]\n#         data = tf.gather(data, LANDMARK_IDX, axis=1)\n        \n        if N_FRAMES < N_FRAMES_NORM:\n            #-----------------------\n            # Pad with reppited values\n#             ratio=tf.math.floordiv(N_FRAMES_NORM,N_FRAMES)+1\n#             data=tf.repeat(data,repeats=ratio,axis=0) # Could be bigger than N_FRAMES_NORM\n#             tensor_index_frame=tf.range(0,N_FRAMES_NORM, delta=1, dtype=tf.int32, name='range')*N_FRAMES*ratio\n#             tensor_index_frame=tf.math.floordiv(tensor_index_frame,N_FRAMES_NORM)\n#             data = tf.gather(data, tensor_index_frame, axis=0)\n            #------------------------\n            # Pad Data With Zeros\n            data = tf.pad(data, [[0, N_FRAMES_NORM-N_FRAMES], [0,0], [0,0]], constant_values=0)\n\n        else:\n            #--------------------\n            # Elije los primeros frames\n            tensor_index_frame=tf.range(0,N_FRAMES_NORM, delta=1, dtype=tf.int32) \n            # -----\n            # Realiza un sampleo uniforme\n#             tensor_index_frame=tf.range(0,N_FRAMES_NORM, delta=1, dtype=tf.int32, name='range')*N_FRAMES\n#             tensor_index_frame=tf.math.floordiv(tensor_index_frame,N_FRAMES_NORM)\n           \n            data = tf.gather(data, tensor_index_frame, axis=0)\n            \n        #complete null with zeros\n        data = tf.where(tf.math.is_nan(data), 0.0, data)\n        \n        data = tf.reshape(data,[N_FRAMES_NORM, len(LANDMARK_IDX)*len(DATA_COLUMNS)])\n\n        return data\n    \npreprocess_layer = PreprocessLayer()","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:56:29.382186Z","iopub.execute_input":"2023-04-30T23:56:29.382595Z","iopub.status.idle":"2023-04-30T23:56:29.398520Z","shell.execute_reply.started":"2023-04-30T23:56:29.382555Z","shell.execute_reply":"2023-04-30T23:56:29.397228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NormalizerLayer(tf.keras.layers.Layer):\n    def __init__(self):\n        super(NormalizerLayer, self).__init__()\n        \n    @tf.function(\n        input_signature=(tf.TensorSpec(shape=[None,543,3], dtype=tf.float32),),\n    )\n    def call(self, data):\n        return normalize(data)\n    \nnormalizer_layer = NormalizerLayer()","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:56:29.431766Z","iopub.execute_input":"2023-04-30T23:56:29.432437Z","iopub.status.idle":"2023-04-30T23:56:29.440990Z","shell.execute_reply.started":"2023-04-30T23:56:29.432398Z","shell.execute_reply":"2023-04-30T23:56:29.439548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TRAIN\n# ORIGINAL DATASET\ntf_dataset_train_len=train_df['path'].shape[0]\nprint(\"Longitud original \"+str(tf_dataset_train_len))\n\ndataset_train=tf.data.Dataset.from_tensor_slices(list(train_df['path'].values))\ndataset_train=dataset_train.map(lambda x:tf_get_features(x))\ndataset_train=dataset_train.map(lambda x:tf.ensure_shape(x, tf.TensorShape([None, 543, 3])))\n# CENTRA LAS PARTES DEL CUERPO\ndataset_train=dataset_train.map(lambda x:tf_get_features_normalize(x)) \n#------------------------------------------------------------------------------------------------- # LABELS\nlabels_train = tf.data.Dataset.from_tensor_slices(train_df['label'].values.reshape(-1,1)) \n#------------------------------------------------------------------------------------------------- # LABELS\n# COMLETA NULOS\ndataset_train=dataset_train.map(lambda x:tf.where(tf.math.is_nan(x), tf.zeros_like(x), x))\n# FLIP AUGMENTATION\nfrac_flip=1\nrandom_state=16\ndataset_augm_flip=tf.data.Dataset.from_tensor_slices(list(train_df['path'].sample(frac=frac_flip,random_state=random_state).values))\ndataset_augm_flip=dataset_augm_flip.map(lambda x:tf_get_features(x))\ndataset_augm_flip=dataset_augm_flip.map(lambda x:tf.ensure_shape(x, tf.TensorShape([None, 543, 3])))\ndataset_augm_flip=dataset_augm_flip.map(lambda x:tf_get_features_augm_flip(x)) # Ya lo centra en el origen ademas de rotarlo\ndataset_augm_flip=dataset_augm_flip.map(lambda x:tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)) \ndataset_train=dataset_train.concatenate(dataset_augm_flip)\n#------------------------------------------------------------------------------------------------- # LABELS\nlabels_augm_flip = tf.data.Dataset.from_tensor_slices(train_df['label'].sample(frac=frac_flip,random_state=random_state).values.reshape(-1,1))\nlabels_train=labels_train.concatenate(labels_augm_flip)\n#------------------------------------------------------------------------------------------------- # LABELS\ntf_dataset_train_len=tf_dataset_train_len+train_df['path'].sample(frac=frac_flip,random_state=random_state).shape[0]\n\nprint(\"Post aumento flip \"+str(tf_dataset_train_len))\n\n# SPACIAL AUGMENTATION (ROTATION)\nfrac_dim=0.15\ncount_dim_augm=0\n\nfor k,angle in enumerate([-20,-10,10,20]):\n    random_state=(k)*42\n    dataset_augm_xy=tf.data.Dataset.from_tensor_slices(list(train_df['path'].sample(frac=frac_dim,random_state=random_state).values))\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf_get_features(x))\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf.ensure_shape(x, tf.TensorShape([None, 543, 3])))\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)) # Es necesario para la rotacion\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf_get_features_rotated_part(x,angle=angle,part='lhand',plane='xy'))\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf_get_features_rotated_part(x,angle=angle,part='rhand',plane='xy'))\n    dataset_train=dataset_train.concatenate(dataset_augm_xy)\n#------------------------------------------------------------------------------------------------- # LABELS    \n    labels_augm_xy = tf.data.Dataset.from_tensor_slices(train_df['label'].sample(frac=frac_dim,random_state=random_state).values.reshape(-1,1))\n    labels_train=labels_train.concatenate(labels_augm_xy)\n#------------------------------------------------------------------------------------------------- # LABELS    \n    count_dim_augm=count_dim_augm+1\nfor k,angle in enumerate([-20,20]):\n    random_state=(k)*34\n    dataset_augm_xy=tf.data.Dataset.from_tensor_slices(list(train_df['path'].sample(frac=frac_dim,random_state=random_state).values))\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf_get_features(x))\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf.ensure_shape(x, tf.TensorShape([None, 543, 3])))\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)) # Es necesario para la rotacion\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf_get_features_rotated_part(x,angle=angle,part='lhand',plane='yz'))\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf_get_features_rotated_part(x,angle=angle,part='rhand',plane='yz'))\n    dataset_train=dataset_train.concatenate(dataset_augm_xy)\n#------------------------------------------------------------------------------------------------- # LABELS    \n    labels_augm_xy = tf.data.Dataset.from_tensor_slices(train_df['label'].sample(frac=frac_dim,random_state=random_state).values.reshape(-1,1))\n    labels_train=labels_train.concatenate(labels_augm_xy)\n#------------------------------------------------------------------------------------------------- # LABELS    \n    count_dim_augm=count_dim_augm+1\nfor k,angle in enumerate([-20,20]):\n    random_state=(k)*34\n    dataset_augm_xy=tf.data.Dataset.from_tensor_slices(list(train_df['path'].sample(frac=frac_dim,random_state=random_state).values))\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf_get_features(x))\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf.ensure_shape(x, tf.TensorShape([None, 543, 3])))\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)) # Es necesario para la rotacion\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf_get_features_rotated_part(x,angle=angle,part='lhand',plane='xz'))\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf_get_features_rotated_part(x,angle=angle,part='rhand',plane='xz'))\n    dataset_train=dataset_train.concatenate(dataset_augm_xy)\n#------------------------------------------------------------------------------------------------- # LABELS    \n    labels_augm_xy = tf.data.Dataset.from_tensor_slices(train_df['label'].sample(frac=frac_dim,random_state=random_state).values.reshape(-1,1))\n    labels_train=labels_train.concatenate(labels_augm_xy)\n#------------------------------------------------------------------------------------------------- # LABELS    \n    count_dim_augm=count_dim_augm+1        \n        \nfor k,angle in enumerate([-5,5]):\n    random_state=k*42\n    dataset_augm_xy=tf.data.Dataset.from_tensor_slices(list(train_df['path'].sample(frac=frac_dim,random_state=random_state).values))\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf_get_features(x))\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf.ensure_shape(x, tf.TensorShape([None, 543, 3])))\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)) # Es necesario para la rotacion\n    dataset_augm_xy=dataset_augm_xy.map(lambda x:tf_get_features_rotated_part(x,angle=angle,part='pose',plane='xy'))\n    dataset_train=dataset_train.concatenate(dataset_augm_xy) #concatena\n#------------------------------------------------------------------------------------------------- # LABELS    \n    labels_augm_xy = tf.data.Dataset.from_tensor_slices(train_df['label'].sample(frac=frac_dim,random_state=random_state).values.reshape(-1,1))\n    labels_train=labels_train.concatenate(labels_augm_xy)\n#------------------------------------------------------------------------------------------------- # LABELS    \n    count_dim_augm=count_dim_augm+1   \n    \nfor j,plane in enumerate(['xy','yz','xz']):\n    for k,angle in enumerate([-10,10]):\n        random_state=(j+k)*27\n        dataset_augm_xy=tf.data.Dataset.from_tensor_slices(list(train_df['path'].sample(frac=frac_dim,random_state=random_state).values))\n        dataset_augm_xy=dataset_augm_xy.map(lambda x:tf_get_features(x))\n        dataset_augm_xy=dataset_augm_xy.map(lambda x:tf.ensure_shape(x, tf.TensorShape([None, 543, 3])))\n        dataset_augm_xy=dataset_augm_xy.map(lambda x:tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)) # Es necesario para la rotacion\n        dataset_augm_xy=dataset_augm_xy.map(lambda x:tf_get_features_rotated_part(x,angle=angle,part='lips',plane=plane))\n        dataset_train=dataset_train.concatenate(dataset_augm_xy) #concatena\n    #------------------------------------------------------------------------------------------------- # LABELS    \n        labels_augm_xy = tf.data.Dataset.from_tensor_slices(train_df['label'].sample(frac=frac_dim,random_state=random_state).values.reshape(-1,1))\n        labels_train=labels_train.concatenate(labels_augm_xy)\n    #------------------------------------------------------------------------------------------------- # LABELS    \n        count_dim_augm=count_dim_augm+1  \n    \n    \n    \ntf_dataset_train_len=tf_dataset_train_len+train_df['path'].sample(frac=frac_dim,random_state=random_state).shape[0]*count_dim_augm\nprint(\"Post aumento rot \"+str(tf_dataset_train_len))\n\n\n# TIME AUGMENTATION\nfrac_time=0.35\nrandom_state=57\ndataset_augm_time=tf.data.Dataset.from_tensor_slices(list(train_df['path'].sample(frac=frac_time,random_state=random_state).values))\ndataset_augm_time=dataset_augm_time.map(lambda x:tf_get_features(x))\ndataset_augm_time=dataset_augm_time.map(lambda x:tf.ensure_shape(x, tf.TensorShape([None, 543, 3])))\ndataset_augm_time=dataset_augm_time.map(lambda x:tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)) # Es necesario para la rotacion\ndataset_augm_time=dataset_augm_time.map(lambda x:tf_get_features_augm_time(x)) #'fast','slow'\ndataset_train=dataset_train.concatenate(dataset_augm_time)\n#------------------------------------------------------------------------------------------------- # LABELS\nlabels_augm_time = tf.data.Dataset.from_tensor_slices(train_df['label'].sample(frac=frac_time,random_state=random_state).values.reshape(-1,1))\nlabels_train=labels_train.concatenate(labels_augm_time) \n#------------------------------------------------------------------------------------------------- # LABELS\n\ntf_dataset_train_len=tf_dataset_train_len+train_df['path'].sample(frac=frac_time,random_state=random_state).shape[0]\n\nprint(\"Post aumento time \"+str(tf_dataset_train_len))\n\n\n# CREATE BATCH SIZE\n# dataset_train=dataset_train.map(lambda x:preprocess_layer(x))\n# dataset_train=dataset_train.map(lambda x:tf.ensure_shape(x, tf.TensorShape([N_FRAMES_NORM,len(LANDMARK_IDX)*len(DATA_COLUMNS)])))\n# dataset_train=dataset_train.map(lambda x:tf.reshape(x,[-1, len(LANDMARK_IDX)*len(DATA_COLUMNS)]))\n\ndataset_train=dataset_train.map(lambda x:tf.gather(x, LANDMARK_IDX, axis=1))\n\ndataset_train=dataset_train.map(lambda x:tf.gather(x, [0,1], axis=-1)) # Se remueve Z\nDATA_COLUMNS= ['x', 'y']\n\n\ndataset_train=dataset_train.map(lambda x:tf.reshape(x,[-1, len(LANDMARK_IDX)*len(DATA_COLUMNS)]))\ndataset_train=dataset_train.take(BATCH_SIZE * (tf_dataset_train_len // BATCH_SIZE)).apply(tf.data.experimental.dense_to_ragged_batch(batch_size=BATCH_SIZE))\n\nlabels_train=labels_train.take(BATCH_SIZE * (tf_dataset_train_len // BATCH_SIZE)).batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:57:51.976667Z","iopub.execute_input":"2023-04-30T23:57:51.977020Z","iopub.status.idle":"2023-04-30T23:57:55.266172Z","shell.execute_reply.started":"2023-04-30T23:57:51.976991Z","shell.execute_reply":"2023-04-30T23:57:55.264999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for batch in dataset_train:\n# #     print(batch.shape)\n#     for tensor in batch:\n# #         print(tensor.numpy()[14,0:3,:])\n# #         print('---------')        \n#         tensor=preprocess_layer(tensor)\n#         print(tensor.shape)\n# #         print(tensor.numpy()[15,0:3,:])\n#     break","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:57:55.267648Z","iopub.execute_input":"2023-04-30T23:57:55.267934Z","iopub.status.idle":"2023-04-30T23:57:55.272961Z","shell.execute_reply.started":"2023-04-30T23:57:55.267908Z","shell.execute_reply":"2023-04-30T23:57:55.271830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# VALIDATION\ntf_dataset_val_len=val_df['path'].shape[0]\n\ndataset_val=tf.data.Dataset.from_tensor_slices(list(val_df['path'].values))\ndataset_val=dataset_val.map(lambda x:tf_get_features(x))\ndataset_val=dataset_val.map(lambda x:tf_get_features_normalize(x))\ndataset_val=dataset_val.map(lambda x:tf.ensure_shape(x, tf.TensorShape([None, 543, 3])))\ndataset_val=dataset_val.map(lambda x:tf.gather(x, LANDMARK_IDX, axis=1))\ndataset_val=dataset_val.map(lambda x:tf.where(tf.math.is_nan(x), tf.zeros_like(x), x))\n# dataset_val=dataset_val.map(lambda x:preprocess_layer(x))\n# dataset_val=dataset_val.map(lambda x:tf.ensure_shape(x, tf.TensorShape([N_FRAMES_NORM,len(LANDMARK_IDX)*len(DATA_COLUMNS)])))\n# dataset_val=dataset_val.map(lambda x:tf.reshape(x,[-1, len(LANDMARK_IDX)*len(DATA_COLUMNS)]))\n\n\ndataset_val=dataset_val.map(lambda x:tf.gather(x, [0,1], axis=-1)) # Se remueve Z\nDATA_COLUMNS= ['x', 'y']\n\ndataset_val=dataset_val.map(lambda x:tf.reshape(x,[-1, len(LANDMARK_IDX)*len(DATA_COLUMNS)]))\ndataset_val=dataset_val.take(BATCH_SIZE * (tf_dataset_val_len // BATCH_SIZE)).apply(tf.data.experimental.dense_to_ragged_batch(batch_size=BATCH_SIZE))\n\nlabels_val = tf.data.Dataset.from_tensor_slices(val_df['label'].values.reshape(-1,1)).take(BATCH_SIZE * (tf_dataset_val_len // BATCH_SIZE)).batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:57:55.274110Z","iopub.execute_input":"2023-04-30T23:57:55.274478Z","iopub.status.idle":"2023-04-30T23:57:55.404396Z","shell.execute_reply.started":"2023-04-30T23:57:55.274440Z","shell.execute_reply":"2023-04-30T23:57:55.402888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving dataset","metadata":{}},{"cell_type":"code","source":"# Sharding could be improved, as the distribution of elements in different shards should optimally be equal.\n# Currently, it will be a sample from a uniform distribution because this is simple to implement\ndef shard_func(*_):\n    return tf.random.uniform(shape=[], maxval=NUM_SHARDS, dtype=tf.int64)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:57:55.407083Z","iopub.execute_input":"2023-04-30T23:57:55.407426Z","iopub.status.idle":"2023-04-30T23:57:55.413261Z","shell.execute_reply.started":"2023-04-30T23:57:55.407395Z","shell.execute_reply":"2023-04-30T23:57:55.412214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataset_train=dataset_train.take(4*64)\n# labels_train=labels_train.take(4*64)\n\n# dataset_val=dataset_val.take(4*64)\n# labels_val=labels_val.take(4*64)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:57:55.414343Z","iopub.execute_input":"2023-04-30T23:57:55.414643Z","iopub.status.idle":"2023-04-30T23:57:55.424989Z","shell.execute_reply.started":"2023-04-30T23:57:55.414617Z","shell.execute_reply":"2023-04-30T23:57:55.423541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# SAVE_PATH_TRAIN='/kaggle.com/datasets/cristiandeblasis/islrRaggedFe/train'\nSAVE_PATH_TRAIN='/kaggle/working/train_dataset'\ntrain_ds = tf.data.Dataset.zip((dataset_train, labels_train))\ntrain_ds.prefetch(tf.data.AUTOTUNE).save(SAVE_PATH_TRAIN, shard_func=shard_func)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T23:57:55.427598Z","iopub.execute_input":"2023-04-30T23:57:55.428568Z","iopub.status.idle":"2023-05-01T02:09:59.485583Z","shell.execute_reply.started":"2023-04-30T23:57:55.428483Z","shell.execute_reply":"2023-05-01T02:09:59.474598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SAVE_PATH_VAL='/kaggle.com/datasets/cristiandeblasis/islrRaggedFe/val'\nSAVE_PATH_VAL='/kaggle/working/val_dataset'\nval_ds = tf.data.Dataset.zip((dataset_val, labels_val))\nval_ds.prefetch(tf.data.AUTOTUNE).save(SAVE_PATH_VAL, shard_func=shard_func)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T02:09:59.502923Z","iopub.execute_input":"2023-05-01T02:09:59.504338Z","iopub.status.idle":"2023-05-01T02:18:54.219954Z","shell.execute_reply.started":"2023-05-01T02:09:59.504237Z","shell.execute_reply":"2023-05-01T02:18:54.218099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"code","source":"class PreprocessBatch(tf.keras.layers.Layer):\n    def __init__(self):\n        super(PreprocessBatch, self).__init__()\n        \n    @tf.function(\n        input_signature=(tf.TensorSpec(shape=[BATCH_SIZE,None,len(LANDMARK_IDX),len(DATA_COLUMNS)], dtype=tf.float32),),\n    )\n    def call(self, data):       \n        N_FRAMES = tf.shape(data)[1]\n        print(data.shape)\n        if N_FRAMES < N_FRAMES_NORM:\n            #-----------------------\n            # Pad with reppited values\n#             ratio=tf.math.floordiv(N_FRAMES_NORM,N_FRAMES)+1\n#             data=tf.repeat(data,repeats=ratio,axis=1) # Could be bigger than N_FRAMES_NORM\n#             tensor_index_frame=tf.range(0,N_FRAMES_NORM, delta=1, dtype=tf.int32, name='range')*N_FRAMES*ratio\n#             tensor_index_frame=tf.math.floordiv(tensor_index_frame,N_FRAMES_NORM)\n#             data = tf.gather(data, tensor_index_frame, axis=1) \n            #------------------------\n            # Pad Data With Zeros\n            data = tf.pad(data, [[0,0],[0, N_FRAMES_NORM-N_FRAMES], [0,0], [0,0]], constant_values=0)            \n        else:\n            #--------------------\n            # Elije los primeros frames\n            tensor_index_frame=tf.range(0,N_FRAMES_NORM, delta=1, dtype=tf.int32) \n            # -----\n            # Realiza un sampleo uniforme\n#             tensor_index_frame=tf.range(0,N_FRAMES_NORM, delta=1, dtype=tf.int32, name='range')*N_FRAMES\n#             tensor_index_frame=tf.math.floordiv(tensor_index_frame,N_FRAMES_NORM)\n           \n            data = tf.gather(data, tensor_index_frame, axis=1)            \n        \n        data = tf.where(tf.math.is_nan(data), 0.0, data)\n#         data = tf.gather(data, [0,1], axis=-1) # Se remueve Z\n        data = tf.reshape(data,[-1,N_FRAMES_NORM, len(LANDMARK_IDX)*len(DATA_COLUMNS)])\n        \n        return data\n    \npreprocess_batch = PreprocessBatch()","metadata":{"execution":{"iopub.status.busy":"2023-05-01T02:18:54.222028Z","iopub.execute_input":"2023-05-01T02:18:54.222642Z","iopub.status.idle":"2023-05-01T02:18:54.255919Z","shell.execute_reply.started":"2023-05-01T02:18:54.222598Z","shell.execute_reply":"2023-05-01T02:18:54.254857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n@tf.function\ndef preparation(ragged_batch):\n    dense_batch = ragged_batch.to_tensor()\n    dense_batch=preprocess_batch(dense_batch)\n    return dense_batch\n\n\n# # Load the data and split to train, validation\n# train_ds = tf.data.Dataset.load(SAVE_PATH_TRAIN).map(lambda x,y:(preparation(x),y)).prefetch(tf.data.AUTOTUNE)\n\n# # Load the data and split to train, validation\n# val_ds = tf.data.Dataset.load(SAVE_PATH_VAL).map(lambda x,y:(preparation(x),y)).prefetch(tf.data.AUTOTUNE)\n\n# Ragged\n# # Load the data and split to train, validation\ntrain_ds = tf.data.Dataset.load(SAVE_PATH_TRAIN).prefetch(tf.data.AUTOTUNE)\n\n# Load the data and split to train, validation\nval_ds = tf.data.Dataset.load(SAVE_PATH_VAL).prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T02:18:54.258274Z","iopub.execute_input":"2023-05-01T02:18:54.259239Z","iopub.status.idle":"2023-05-01T02:18:54.341053Z","shell.execute_reply.started":"2023-05-01T02:18:54.259188Z","shell.execute_reply":"2023-05-01T02:18:54.339774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for b in train_ds:\n#     print(b[0].shape)\n#     break","metadata":{"execution":{"iopub.status.busy":"2023-05-01T02:18:54.347199Z","iopub.execute_input":"2023-05-01T02:18:54.347552Z","iopub.status.idle":"2023-05-01T02:18:54.353339Z","shell.execute_reply.started":"2023-05-01T02:18:54.347503Z","shell.execute_reply":"2023-05-01T02:18:54.351983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model definition","metadata":{}},{"cell_type":"code","source":"# # Initiailizers\n# INIT_HE_UNIFORM = tf.keras.initializers.he_uniform\n# INIT_GLOROT_UNIFORM = tf.keras.initializers.glorot_uniform\n# INIT_ZEROS = tf.keras.initializers.constant(0.0)\n# # Activations\n# GELU = tf.keras.activations.gelu\n\n# class LandmarkEmbedding(tf.keras.Model):\n#     def __init__(self, units, name):\n#         super(LandmarkEmbedding, self).__init__(name=f'{name}_embedding')\n#         self.units = units\n        \n#     def build(self, input_shape):\n#         # Embedding for missing landmark in frame, initizlied with zeros\n#         self.empty_embedding = self.add_weight(\n#             name=f'{self.name}_empty_embedding',\n#             shape=[self.units],\n#             initializer=INIT_ZEROS,\n#         )\n#         # Embedding\n#         self.dense = tf.keras.Sequential([\n#             tf.keras.layers.Dense(self.units, name=f'{self.name}_dense_1', use_bias=False, kernel_initializer=INIT_GLOROT_UNIFORM),\n#             tf.keras.layers.Activation(GELU),\n#             tf.keras.layers.Dense(self.units, name=f'{self.name}_dense_2', use_bias=False, kernel_initializer=INIT_HE_UNIFORM),\n#         ], name=f'{self.name}_dense')\n\n#     def call(self, x):\n#         return tf.where(\n#                 # Checks whether landmark is missing in frame\n#                 tf.reduce_sum(x, axis=2, keepdims=True) == 0,\n#                 # If so, the empty embedding is used\n#                 self.dense(x),#self.empty_embedding,\n#                 # Otherwise the landmark data is embedded\n#                 self.dense(x),\n#             )","metadata":{"execution":{"iopub.status.busy":"2023-05-01T02:18:54.355615Z","iopub.execute_input":"2023-05-01T02:18:54.356092Z","iopub.status.idle":"2023-05-01T02:18:54.370325Z","shell.execute_reply.started":"2023-05-01T02:18:54.356056Z","shell.execute_reply":"2023-05-01T02:18:54.368390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Dense layer units for landmarks\n# LIPS_UNITS = 384\n# HANDS_UNITS = 384\n# POSE_UNITS = 384\n# # final embedding and transformer embedding size\n# UNITS = 256\n\n# class PositionalEmbedding(layers.Layer):\n#     def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n#         super().__init__(**kwargs)\n# #         self.token_embeddings = layers.Embedding(input_dim=input_dim, output_dim=output_dim)\n#         self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=output_dim)\n#         self.sequence_length = sequence_length\n#         self.input_dim = input_dim\n#         self.output_dim = output_dim\n        \n#         # Se incluye embedding for landmarks\n#         # Embedding layer for Landmarks\n#         self.lips_embedding = LandmarkEmbedding(LIPS_UNITS, 'lips')\n#         self.left_hand_embedding = LandmarkEmbedding(HANDS_UNITS, 'left_hand')\n#         self.pose_embedding = LandmarkEmbedding(POSE_UNITS, 'pose')\n#         self.right_hand_embedding = LandmarkEmbedding(HANDS_UNITS, 'right_hand')\n#         # Landmark Weights\n#         self.landmark_weights = tf.Variable(tf.zeros([4], dtype=tf.float32), name='landmark_weights')\n#         # Fully Connected Layers for combined landmarks\n#         self.fc = tf.keras.Sequential([\n#             tf.keras.layers.Dense(UNITS, name='fully_connected_1', use_bias=False, kernel_initializer=INIT_GLOROT_UNIFORM),\n#             tf.keras.layers.Activation(GELU),\n#             tf.keras.layers.Dense(UNITS, name='fully_connected_2', use_bias=False, kernel_initializer=INIT_HE_UNIFORM),\n#         ], name='fc')\n    \n#     def call(self, lips0,left_hand0,pose0,right_hand0):\n#         length = self.sequence_length# tf.shape(inputs)[-1]\n#         positions = tf.range(start=0, limit=length, delta=1)\n# #         embedded_tokens = self.token_embeddings(inputs)\n        \n\n#         # Lips\n#         lips_embedding = self.lips_embedding(lips0)\n#         # Left Hand\n#         left_hand_embedding = self.left_hand_embedding(left_hand0)\n#         # Pose\n#         pose_embedding = self.pose_embedding(pose0)\n#         # Right Hand\n#         right_hand_embedding = self.right_hand_embedding(right_hand0)\n#         # Merge Embeddings of all landmarks with mean pooling\n#         x = tf.stack((\n#             lips_embedding, left_hand_embedding, pose_embedding,right_hand_embedding\n#         ), axis=3) #(None, 64, 384, 4)\n#         print(x.shape)\n#         x = x * tf.nn.softmax(self.landmark_weights) #(None, 64, 384, 4)\n#         print(x.shape)\n#         x = tf.reduce_sum(x, axis=3) #(None, 64, 384) \n#         print(x.shape)\n#         # Fully Connected Layers\n#         x = self.fc(x) #(None, 64, 256)\n#         print(x.shape)\n        \n\n#         embedded_positions = self.position_embeddings(positions)\n#         return x + embedded_positions\n    \n# #     def compute_mask(self, inputs, mask=None):\n# # #         mask=tf.ones([1,16],dtype=tf.dtypes.float32)\n# #         mask=tf.math.not_equal(tf.reduce_sum(inputs, axis=[-1], keepdims=False), 0)\n# #         return mask\n# #         return tf.math.not_equal(tf.reduce_sum(data, axis=[-1], keepdims=False), 0)\n    \n#     def get_config(self):\n#         config = super().get_config()\n#         config.update({\"output_dim\": self.output_dim,\n#                        \"sequence_length\": self.sequence_length,\n#                        \"input_dim\": self.input_dim})\n#         return config","metadata":{"execution":{"iopub.status.busy":"2023-05-01T02:18:54.374563Z","iopub.execute_input":"2023-05-01T02:18:54.375085Z","iopub.status.idle":"2023-05-01T02:18:54.386235Z","shell.execute_reply.started":"2023-05-01T02:18:54.375045Z","shell.execute_reply":"2023-05-01T02:18:54.385038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MLP_RATIO=2\n# class TransformerEncoder(layers.Layer):\n#     def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n#         super().__init__(**kwargs)\n#         self.embed_dim = embed_dim\n#         self.dense_dim = dense_dim\n#         self.num_heads = num_heads\n#         self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n# #         self.dense_proj = tf.keras.Sequential([layers.Dense(dense_dim, activation=\"relu\",kernel_initializer=tf.keras.initializers.he_uniform),\n# #                                                layers.Dense(embed_dim, kernel_initializer=tf.keras.initializers.glorot_uniform)])\n#         self.dense_proj = tf.keras.Sequential([layers.Dense(UNITS*MLP_RATIO,activation=GELU,\n#                                                             kernel_initializer=tf.keras.initializers.he_uniform),\n#                                                layers.Dense(UNITS, \n#                                                             kernel_initializer=tf.keras.initializers.glorot_uniform)])        \n#         self.layernorm_1 = layers.LayerNormalization()\n#         self.layernorm_2 = layers.LayerNormalization()\n# #         self.supports_masking = True #https://keras.io/guides/understanding_masking_and_padding/\n        \n#     def call(self, inputs, mask=None):\n# #         if mask is not None:\n# # #             mask = mask[:,tf.newaxis,:]\n# #             mask=tf.expand_dims(mask, axis=2)       \n        \n#         attention_output = self.attention(inputs, inputs, attention_mask=mask)\n#         proj_input = self.layernorm_1(inputs + attention_output)\n#         proj_output = self.dense_proj(proj_input)\n#         return self.layernorm_2(proj_input + proj_output)\n\n#     def get_config(self):\n#         config = super().get_config()\n#         config.update({\"embed_dim\": self.embed_dim,\"num_heads\": self.num_heads,\"dense_dim\": self.dense_dim,})\n#         return config","metadata":{"execution":{"iopub.status.busy":"2023-05-01T02:18:54.388799Z","iopub.execute_input":"2023-05-01T02:18:54.389191Z","iopub.status.idle":"2023-05-01T02:18:54.408728Z","shell.execute_reply.started":"2023-05-01T02:18:54.389156Z","shell.execute_reply":"2023-05-01T02:18:54.406534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # sequence_length = 600\n# embed_dim = UNITS\n# num_heads = 4\n# dense_dim = 64 \n# sequence_length=N_FRAMES_NORM\n# vocab_size=None\n\n# transformer_layer1=TransformerEncoder(embed_dim, dense_dim, num_heads)\n# transformer_layer2=TransformerEncoder(embed_dim, dense_dim, num_heads)\n\n# inputs = tf.keras.Input(shape=(N_FRAMES_NORM,len(LANDMARK_IDX)*len(DATA_COLUMNS)), dtype=\"float32\",name=\"input\")\n\n# mask1=tf.math.not_equal(tf.reduce_sum(inputs, axis=[-1], keepdims=False), 0)\n# mask1=tf.expand_dims(mask1, axis=2)  \n\n# lips0=tf.gather(inputs, tf.range(START_LIPS*len(DATA_COLUMNS),STOP_LIPS*len(DATA_COLUMNS)), axis=-1)\n# left_hand0=tf.gather(inputs, tf.range(START_LHANDS*len(DATA_COLUMNS),STOP_LHANDS*len(DATA_COLUMNS)), axis=-1)\n# pose0=tf.gather(inputs, tf.range(START_POSE*len(DATA_COLUMNS),STOP_POSE*len(DATA_COLUMNS)), axis=-1)\n# right_hand0=tf.gather(inputs, tf.range(START_RHANDS*len(DATA_COLUMNS),STOP_RHANDS*len(DATA_COLUMNS)), axis=-1)\n\n# x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(lips0,left_hand0,pose0,right_hand0)\n# # x = layers.Embedding(vocab_size, embed_dim)(x)\n# x = transformer_layer1(x,mask1) # Utiliza el vector de entrada como embeding\n# # x = transformer_layer2(x,mask1) \n# # x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x) \n# # x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n# x = layers.GlobalMaxPooling1D()(x)\n# x = layers.Dropout(0.2)(x)\n# outputs = layers.Dense(CLASS_COUNT, activation=\"softmax\")(x)\n# model = tf.keras.Model(inputs, outputs)\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-01T02:18:54.410976Z","iopub.execute_input":"2023-05-01T02:18:54.411358Z","iopub.status.idle":"2023-05-01T02:18:54.428816Z","shell.execute_reply.started":"2023-05-01T02:18:54.411315Z","shell.execute_reply":"2023-05-01T02:18:54.426462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_tensor = Input(shape=(None,len(LANDMARK_IDX)*len(DATA_COLUMNS)), ragged=True)\n\nx = layers.Dense(512)(input_tensor)\nx = layers.LayerNormalization(axis=2)(x)\nx = layers.Activation(\"relu\")(x)\nx = layers.Dropout(0.2)(x)\n\nx = layers.Dense(256)(x)\nx = layers.LayerNormalization(axis=2)(x)\nx = layers.Activation(\"relu\")(x)\nx = layers.Dropout(0.2)(x)\n\nx = layers.Dense(128)(x)\nx = layers.LayerNormalization(axis=2)(x)\nx = layers.Activation(\"relu\")(x)\nx = layers.Dropout(0.2)(x)\n\nx = LSTM(96)(x)\noutput_tensor = Dense(CLASS_COUNT, activation='softmax')(x)\n\nmodel = Model(input_tensor, output_tensor)\n\nmodel.compile(\n    loss=\"sparse_categorical_crossentropy\",\n    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n    metrics=[\"accuracy\"],\n)\n\nmodel.summary(expand_nested=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T02:18:54.430721Z","iopub.execute_input":"2023-05-01T02:18:54.431219Z","iopub.status.idle":"2023-05-01T02:18:56.114062Z","shell.execute_reply.started":"2023-05-01T02:18:54.431169Z","shell.execute_reply":"2023-05-01T02:18:56.112354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Funciones de monitoreo\n\nes_callback = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\", patience=20, restore_best_weights=True\n)\n\ncheckpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    \"./LSTM_model\",\n    save_best_only=True,\n    restore_best_weights=True,\n    monitor=\"val_accuracy\",\n    mode=\"max\",\n    verbose=False,\n)\n\ncb_list = [checkpoint_callback,es_callback]","metadata":{"execution":{"iopub.status.busy":"2023-05-01T02:18:56.115619Z","iopub.execute_input":"2023-05-01T02:18:56.115939Z","iopub.status.idle":"2023-05-01T02:18:56.123534Z","shell.execute_reply.started":"2023-05-01T02:18:56.115907Z","shell.execute_reply":"2023-05-01T02:18:56.121598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=\"sparse_categorical_crossentropy\",\n              optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n              metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-05-01T02:18:56.125681Z","iopub.execute_input":"2023-05-01T02:18:56.126237Z","iopub.status.idle":"2023-05-01T02:18:56.148264Z","shell.execute_reply.started":"2023-05-01T02:18:56.126190Z","shell.execute_reply":"2023-05-01T02:18:56.146898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(train_ds, validation_data=val_ds, epochs=80,callbacks = cb_list)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T02:18:56.347398Z","iopub.execute_input":"2023-05-01T02:18:56.347799Z","iopub.status.idle":"2023-05-01T04:34:51.831094Z","shell.execute_reply.started":"2023-05-01T02:18:56.347769Z","shell.execute_reply":"2023-05-01T04:34:51.827802Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import scipy\n\n# # Landmark Weights\n# for w in model.get_layer('positional_embedding').weights:\n#     if 'landmark_weights' in w.name:\n#         weights = scipy.special.softmax(w)\n\n# landmarks = ['lips_embedding', 'left_hand_embedding', 'pose_embedding','right_hand_embedding']\n\n# for w, lm in zip(weights, landmarks):\n#     print(w)\n#     print(f'{lm} weight: {(w*100):.1f}%')","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:34:51.835867Z","iopub.status.idle":"2023-05-01T04:34:51.836381Z","shell.execute_reply.started":"2023-05-01T04:34:51.836163Z","shell.execute_reply":"2023-05-01T04:34:51.836188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"# model = tf.keras.models.load_model(\"./LSTM_model\", custom_objects={'PositionalEmbedding': PositionalEmbedding})\nmodel = tf.keras.models.load_model(\"./LSTM_model\")","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:35:06.038701Z","iopub.execute_input":"2023-05-01T04:35:06.039095Z","iopub.status.idle":"2023-05-01T04:35:09.666724Z","shell.execute_reply.started":"2023-05-01T04:35:06.039063Z","shell.execute_reply":"2023-05-01T04:35:09.665561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TFLite model for submission\nclass TFLiteModel(tf.Module):\n    def __init__(self, model):\n        super(TFLiteModel, self).__init__()\n\n        # Load the feature generation and main models\n#         self.preprocess_layer = preprocess_layer\n        self.normalizer_layer = normalizer_layer\n        self.model = model\n    \n    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')])\n    def __call__(self, inputs):\n        # Preprocess Data\n        x = self.normalizer_layer(inputs)\n        x=tf.gather(x, [0,1], axis=-1)\n        DATA_COLUMNS=['X','Y']\n        x=tf.gather(x, LANDMARK_IDX, axis=1)\n        x=tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n        x=tf.reshape(x,[-1, len(LANDMARK_IDX)*len(DATA_COLUMNS)])\n        # Add Batch Dimension\n        x = tf.expand_dims(x, axis=0)\n     \n        # Make Prediction\n        outputs = self.model(x)\n        print(outputs.shape)\n        # Squeeze Output 1x250 -> 250\n        outputs = tf.squeeze(outputs, axis=0)\n\n        # Return a dictionary with the output tensor\n        return {'outputs': outputs}\n\n# Define TF Lite Model\ntflite_keras_model = TFLiteModel(model)\n\n# Sanity Check\n# k=34\n# demo_raw_data = load_relevant_data_subset(metadata.path[k])\n# print(f'demo_raw_data shape: {demo_raw_data.shape}, dtype: {demo_raw_data.dtype}')\n# demo_output = tflite_keras_model(demo_raw_data)[\"outputs\"]\n# print(f'demo_output shape: {demo_output.shape}, dtype: {demo_output.dtype}')\n# demo_prediction = demo_output.numpy().argmax()\n# print(f'demo_prediction: {demo_prediction}, correct: {s2p_map[metadata.sign[k]]}')","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:35:45.570907Z","iopub.execute_input":"2023-05-01T04:35:45.571348Z","iopub.status.idle":"2023-05-01T04:35:45.584504Z","shell.execute_reply.started":"2023-05-01T04:35:45.571310Z","shell.execute_reply":"2023-05-01T04:35:45.583342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Model Converter\nkeras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflite_keras_model)\n# Convert Model\ntflite_model = keras_model_converter.convert()\n# Write Model\nwith open('/kaggle/working/model.tflite', 'wb') as f:\n    f.write(tflite_model)\n    \n# Zip Model\n!zip submission.zip /kaggle/working/model.tflite","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:35:45.855331Z","iopub.execute_input":"2023-05-01T04:35:45.855780Z","iopub.status.idle":"2023-05-01T04:35:56.051990Z","shell.execute_reply.started":"2023-05-01T04:35:45.855742Z","shell.execute_reply":"2023-05-01T04:35:56.049864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Safe validation","metadata":{}},{"cell_type":"code","source":"# !pip install tflite-runtime\n# import tflite_runtime.interpreter as tflite\n# import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:36:08.320400Z","iopub.execute_input":"2023-05-01T04:36:08.320861Z","iopub.status.idle":"2023-05-01T04:36:20.747469Z","shell.execute_reply.started":"2023-05-01T04:36:08.320824Z","shell.execute_reply":"2023-05-01T04:36:20.746087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metadata = pd.read_csv(\"/kaggle/input/asl-signs/train.csv\")\n# with open(\"/kaggle/input/asl-signs/sign_to_prediction_index_map.json\") as f:\n#     sign_map = json.load(f)\n# sign_list = list(sign_map.keys())","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:36:20.750263Z","iopub.execute_input":"2023-05-01T04:36:20.751261Z","iopub.status.idle":"2023-05-01T04:36:21.015535Z","shell.execute_reply.started":"2023-05-01T04:36:20.751207Z","shell.execute_reply":"2023-05-01T04:36:21.012698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_path = \"model.tflite\"\n# interpreter = tflite.Interpreter(model_path)\n# found_signatures = list(interpreter.get_signature_list().keys())\n# # if REQUIRED_SIGNATURE not in found_signatures:\n# #     raise KernelEvalException('Required input signature not found.')\n# prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n\n# y_trues = []\n# y_preds = []\n# for i in range(100):\n#     data = load_relevant_data_subset(metadata.path[i])\n#     output = prediction_fn(inputs=data)\n#     sign_pred = np.argmax(output[\"outputs\"])\n    \n#     y_trues.append(metadata.sign[i])\n#     y_preds.append(sign_list[sign_pred])","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:36:21.016877Z","iopub.execute_input":"2023-05-01T04:36:21.017855Z","iopub.status.idle":"2023-05-01T04:36:23.529936Z","shell.execute_reply.started":"2023-05-01T04:36:21.017826Z","shell.execute_reply":"2023-05-01T04:36:23.528341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_num = [sign_map[sign] for sign in y_trues]\n# y_prednum = [sign_map[sign] for sign in y_preds]\n# confmat = tf.math.confusion_matrix(y_num,y_prednum)\n# plt.imshow(confmat, cmap=\"binary\")","metadata":{"execution":{"iopub.status.busy":"2023-05-01T04:36:23.532187Z","iopub.execute_input":"2023-05-01T04:36:23.532503Z","iopub.status.idle":"2023-05-01T04:36:23.818892Z","shell.execute_reply.started":"2023-05-01T04:36:23.532475Z","shell.execute_reply":"2023-05-01T04:36:23.817330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}